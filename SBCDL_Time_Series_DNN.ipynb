{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThilakBS/GTech-Seth-Bonder/blob/main/SBCDL_Time_Series_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3077b84-9815-4835-aa91-4c80b17d36aa",
      "metadata": {
        "id": "a3077b84-9815-4835-aa91-4c80b17d36aa"
      },
      "source": [
        "# This project is about predicting the temperature 12 hours from now given a set of past features. The data is from Germany for about 7 years at the hourly granularity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4089d35f",
      "metadata": {
        "id": "4089d35f"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.utils import timeseries_dataset_from_array\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e9b0d1-45ff-45df-97bf-dd89bb056eea",
      "metadata": {
        "id": "23e9b0d1-45ff-45df-97bf-dd89bb056eea"
      },
      "source": [
        "# Read the data from the csv file (do not worry); the header gives you the meaning of the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf8e70fa-99f8-4728-87dc-da547bd1eb4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf8e70fa-99f8-4728-87dc-da547bd1eb4d",
        "outputId": "db328f66-0416-490d-8491-8b0974a2e898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n"
          ]
        }
      ],
      "source": [
        "fname = os.path.join(\"jena_climate_2009_2016.csv\")\n",
        "with open(fname) as f:\n",
        "    data = f.read()\n",
        "lines = data.split(\"\\n\")\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "print(header)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f934cc8d-3a67-4a9d-b944-f4a8c621edd0",
      "metadata": {
        "id": "f934cc8d-3a67-4a9d-b944-f4a8c621edd0"
      },
      "source": [
        "# These lines compute the temperature (the target) and the raw_data (the features). The raw_data also contains the temperature since past temperature will be used to predict the next temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a58a4dab-21d0-4465-87e5-acdb03ae27cf",
      "metadata": {
        "id": "a58a4dab-21d0-4465-87e5-acdb03ae27cf"
      },
      "outputs": [],
      "source": [
        "temperature = np.zeros((len(lines),))\n",
        "raw_data = np.zeros((len(lines), len(header) - 1))\n",
        "for i, line in enumerate(lines):\n",
        "    values = [float(x) for x in line.split(\",\")[1:]]\n",
        "    temperature[i] = values[1]\n",
        "    raw_data[i, :] = values[:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2876719e-570c-46ce-9446-5c4d20023b02",
      "metadata": {
        "id": "2876719e-570c-46ce-9446-5c4d20023b02"
      },
      "source": [
        "# Normalize the raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9cbbbda-7a49-4725-9a74-978b6f621d78",
      "metadata": {
        "id": "f9cbbbda-7a49-4725-9a74-978b6f621d78"
      },
      "outputs": [],
      "source": [
        "mean = raw_data[:num_train_samples].mean(axis=0)\n",
        "raw_data -= mean\n",
        "std = raw_data[:num_train_samples].std(axis=0)\n",
        "raw_data /= std"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58fc05f6-ae30-4d49-9a24-36fb76c178b0",
      "metadata": {
        "id": "58fc05f6-ae30-4d49-9a24-36fb76c178b0"
      },
      "source": [
        "# Define the proper number of samples for the training, testing, and validation sets; do not create new sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54ee745e-438c-4efc-ac64-61445cdded38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54ee745e-438c-4efc-ac64-61445cdded38",
        "outputId": "3ed76445-d083-41f4-eea2-a6943162854c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_train_samples: 30000\n",
            "num_val_samples: 10000\n",
            "num_test_samples: 10000\n",
            "total: 50000\n"
          ]
        }
      ],
      "source": [
        "num_train_samples = 30000\n",
        "num_val_samples = 10000\n",
        "num_test_samples = 10000\n",
        "print(\"num_train_samples:\", num_train_samples)\n",
        "print(\"num_val_samples:\", num_val_samples)\n",
        "print(\"num_test_samples:\", num_test_samples)\n",
        "print(\"total:\",num_train_samples + num_val_samples + num_test_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e936a41-4520-46bb-9c1c-48a9fdbb517b",
      "metadata": {
        "id": "8e936a41-4520-46bb-9c1c-48a9fdbb517b"
      },
      "source": [
        "# This is the utility code to generate the data as discussed in the videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3978addb-31db-4211-b304-a1f7b1d8113d",
      "metadata": {
        "id": "3978addb-31db-4211-b304-a1f7b1d8113d"
      },
      "outputs": [],
      "source": [
        "sequence_length = 120\n",
        "lookahead = 12 # predict 12 hours in the future\n",
        "delay = (sequence_length + lookahead - 1)\n",
        "batch_size = 256\n",
        "\n",
        "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sequence_length=sequence_length,\n",
        "    batch_size=batch_size,\n",
        "    start_index=0,\n",
        "    end_index=num_train_samples-1)\n",
        "\n",
        "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sequence_length=sequence_length,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples,\n",
        "    end_index=num_train_samples + num_val_samples-1)\n",
        "\n",
        "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sequence_length=sequence_length,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples + num_val_samples,\n",
        "    end_index=num_train_samples + num_val_samples + num_test_samples-delay-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc4a0dc2-730c-4ce4-b135-754e6539f5c0",
      "metadata": {
        "id": "bc4a0dc2-730c-4ce4-b135-754e6539f5c0"
      },
      "source": [
        "# Now define the DNN model, plot the results;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74005da7-e896-4c42-bcc3-bd7a1f2e7198",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "74005da7-e896-4c42-bcc3-bd7a1f2e7198",
        "outputId": "24adfe36-364f-4c60-9cea-d80448d22dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 21.2050 - mae: 3.5717 - val_loss: 11.4160 - val_mae: 2.7801\n",
            "Epoch 2/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 10.2195 - mae: 2.4633 - val_loss: 6.7522 - val_mae: 2.0886\n",
            "Epoch 3/800\n",
            "117/117 [==============================] - 5s 47ms/step - loss: 9.1061 - mae: 2.1735 - val_loss: 5.2429 - val_mae: 1.8048\n",
            "Epoch 4/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 8.4570 - mae: 2.0377 - val_loss: 4.3433 - val_mae: 1.6492\n",
            "Epoch 5/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 8.4101 - mae: 1.9720 - val_loss: 4.6617 - val_mae: 1.7282\n",
            "Epoch 6/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 8.1029 - mae: 1.9339 - val_loss: 4.7310 - val_mae: 1.7383\n",
            "Epoch 7/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 7.4423 - mae: 1.8764 - val_loss: 4.9443 - val_mae: 1.8166\n",
            "Epoch 8/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 6.6873 - mae: 1.7822 - val_loss: 4.6099 - val_mae: 1.7283\n",
            "Epoch 9/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 6.1840 - mae: 1.7359 - val_loss: 4.2766 - val_mae: 1.6401\n",
            "Epoch 10/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 6.4117 - mae: 1.7843 - val_loss: 5.5540 - val_mae: 1.9231\n",
            "Epoch 11/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 6.4904 - mae: 1.7234 - val_loss: 5.5045 - val_mae: 1.9226\n",
            "Epoch 12/800\n",
            "117/117 [==============================] - 7s 61ms/step - loss: 5.6702 - mae: 1.6991 - val_loss: 5.7677 - val_mae: 1.9807\n",
            "Epoch 13/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 5.6369 - mae: 1.6512 - val_loss: 5.7507 - val_mae: 1.9841\n",
            "Epoch 14/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 5.3715 - mae: 1.6362 - val_loss: 4.7685 - val_mae: 1.7760\n",
            "Epoch 15/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 5.8052 - mae: 1.6456 - val_loss: 4.6886 - val_mae: 1.7750\n",
            "Epoch 16/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 5.2933 - mae: 1.6032 - val_loss: 4.3819 - val_mae: 1.7011\n",
            "Epoch 17/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 5.6019 - mae: 1.6033 - val_loss: 3.9862 - val_mae: 1.5743\n",
            "Epoch 18/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 5.0169 - mae: 1.5761 - val_loss: 4.0210 - val_mae: 1.6081\n",
            "Epoch 19/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 4.6230 - mae: 1.5415 - val_loss: 4.2704 - val_mae: 1.6676\n",
            "Epoch 20/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 5.1237 - mae: 1.5634 - val_loss: 3.9123 - val_mae: 1.5645\n",
            "Epoch 21/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 4.9535 - mae: 1.5443 - val_loss: 4.2397 - val_mae: 1.6449\n",
            "Epoch 22/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 4.8337 - mae: 1.5395 - val_loss: 3.9661 - val_mae: 1.5756\n",
            "Epoch 23/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 4.8397 - mae: 1.5294 - val_loss: 3.9738 - val_mae: 1.5783\n",
            "Epoch 24/800\n",
            "117/117 [==============================] - 6s 56ms/step - loss: 4.7226 - mae: 1.5200 - val_loss: 3.8836 - val_mae: 1.5711\n",
            "Epoch 25/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 4.6884 - mae: 1.5071 - val_loss: 3.9446 - val_mae: 1.5629\n",
            "Epoch 26/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 4.6347 - mae: 1.4935 - val_loss: 3.9669 - val_mae: 1.5877\n",
            "Epoch 27/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 4.5378 - mae: 1.4652 - val_loss: 3.8907 - val_mae: 1.5395\n",
            "Epoch 28/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 4.5128 - mae: 1.4738 - val_loss: 4.0308 - val_mae: 1.6187\n",
            "Epoch 29/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 4.6871 - mae: 1.4632 - val_loss: 5.8049 - val_mae: 1.9970\n",
            "Epoch 30/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 3.9109 - mae: 1.4397 - val_loss: 4.1702 - val_mae: 1.6624\n",
            "Epoch 31/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 4.4137 - mae: 1.4308 - val_loss: 3.9915 - val_mae: 1.6085\n",
            "Epoch 32/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 4.4397 - mae: 1.4443 - val_loss: 5.2317 - val_mae: 1.8715\n",
            "Epoch 33/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 4.0744 - mae: 1.4144 - val_loss: 3.9793 - val_mae: 1.5880\n",
            "Epoch 34/800\n",
            "117/117 [==============================] - 6s 48ms/step - loss: 4.0209 - mae: 1.3935 - val_loss: 3.7398 - val_mae: 1.5274\n",
            "Epoch 35/800\n",
            "117/117 [==============================] - 6s 53ms/step - loss: 4.0035 - mae: 1.3809 - val_loss: 3.8903 - val_mae: 1.5790\n",
            "Epoch 36/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 4.1704 - mae: 1.3951 - val_loss: 5.4683 - val_mae: 1.9497\n",
            "Epoch 37/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 3.7987 - mae: 1.3876 - val_loss: 3.8461 - val_mae: 1.5618\n",
            "Epoch 38/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 3.7918 - mae: 1.3570 - val_loss: 3.4212 - val_mae: 1.4440\n",
            "Epoch 39/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 3.7161 - mae: 1.3532 - val_loss: 3.9182 - val_mae: 1.5919\n",
            "Epoch 40/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 3.7170 - mae: 1.3416 - val_loss: 3.6433 - val_mae: 1.5144\n",
            "Epoch 41/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 3.7036 - mae: 1.3254 - val_loss: 4.0616 - val_mae: 1.6439\n",
            "Epoch 42/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 3.3547 - mae: 1.3304 - val_loss: 3.6581 - val_mae: 1.5142\n",
            "Epoch 43/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 3.6836 - mae: 1.3479 - val_loss: 6.1372 - val_mae: 2.1086\n",
            "Epoch 44/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 3.5031 - mae: 1.3284 - val_loss: 3.8062 - val_mae: 1.5745\n",
            "Epoch 45/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 3.3862 - mae: 1.3072 - val_loss: 5.5177 - val_mae: 1.9712\n",
            "Epoch 46/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 3.4330 - mae: 1.3106 - val_loss: 4.0182 - val_mae: 1.6484\n",
            "Epoch 47/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 3.1751 - mae: 1.2903 - val_loss: 3.9282 - val_mae: 1.6268\n",
            "Epoch 48/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 3.2337 - mae: 1.2873 - val_loss: 4.5520 - val_mae: 1.7802\n",
            "Epoch 49/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 3.3587 - mae: 1.3231 - val_loss: 4.9328 - val_mae: 1.8708\n",
            "Epoch 50/800\n",
            "117/117 [==============================] - 7s 61ms/step - loss: 3.2176 - mae: 1.2909 - val_loss: 5.4037 - val_mae: 1.9489\n",
            "Epoch 51/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 3.3091 - mae: 1.2934 - val_loss: 3.5875 - val_mae: 1.5191\n",
            "Epoch 52/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 3.2111 - mae: 1.2830 - val_loss: 5.6171 - val_mae: 1.9738\n",
            "Epoch 53/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 3.2235 - mae: 1.2921 - val_loss: 5.0636 - val_mae: 1.8904\n",
            "Epoch 54/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 2.7969 - mae: 1.2435 - val_loss: 4.3747 - val_mae: 1.7232\n",
            "Epoch 55/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 3.0208 - mae: 1.2416 - val_loss: 6.0162 - val_mae: 2.0741\n",
            "Epoch 56/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 3.0367 - mae: 1.2468 - val_loss: 4.4377 - val_mae: 1.7501\n",
            "Epoch 57/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 3.1112 - mae: 1.2498 - val_loss: 5.8564 - val_mae: 2.0454\n",
            "Epoch 58/800\n",
            "117/117 [==============================] - 6s 49ms/step - loss: 3.0446 - mae: 1.2632 - val_loss: 4.7090 - val_mae: 1.8160\n",
            "Epoch 59/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.9423 - mae: 1.2278 - val_loss: 5.6630 - val_mae: 1.9985\n",
            "Epoch 60/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.9016 - mae: 1.2286 - val_loss: 4.4211 - val_mae: 1.7415\n",
            "Epoch 61/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.8902 - mae: 1.2185 - val_loss: 3.9890 - val_mae: 1.6202\n",
            "Epoch 62/800\n",
            "117/117 [==============================] - 6s 52ms/step - loss: 2.9356 - mae: 1.2361 - val_loss: 3.9898 - val_mae: 1.6251\n",
            "Epoch 63/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.8899 - mae: 1.2259 - val_loss: 5.1594 - val_mae: 1.9067\n",
            "Epoch 64/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 2.5856 - mae: 1.2015 - val_loss: 5.4574 - val_mae: 1.9767\n",
            "Epoch 65/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.8587 - mae: 1.2256 - val_loss: 4.5090 - val_mae: 1.7603\n",
            "Epoch 66/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.5163 - mae: 1.1849 - val_loss: 5.3630 - val_mae: 1.9592\n",
            "Epoch 67/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.8082 - mae: 1.2062 - val_loss: 4.8707 - val_mae: 1.8495\n",
            "Epoch 68/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.7816 - mae: 1.1958 - val_loss: 4.4590 - val_mae: 1.7434\n",
            "Epoch 69/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 2.6511 - mae: 1.1796 - val_loss: 4.9666 - val_mae: 1.8711\n",
            "Epoch 70/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.7686 - mae: 1.1995 - val_loss: 4.4197 - val_mae: 1.7367\n",
            "Epoch 71/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.6060 - mae: 1.1769 - val_loss: 5.1642 - val_mae: 1.9152\n",
            "Epoch 72/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.7158 - mae: 1.1914 - val_loss: 4.8400 - val_mae: 1.8332\n",
            "Epoch 73/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.5199 - mae: 1.1730 - val_loss: 5.3531 - val_mae: 1.9556\n",
            "Epoch 74/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.5984 - mae: 1.1722 - val_loss: 4.5969 - val_mae: 1.7807\n",
            "Epoch 75/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.7081 - mae: 1.1836 - val_loss: 4.4612 - val_mae: 1.7431\n",
            "Epoch 76/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.4588 - mae: 1.1512 - val_loss: 5.3867 - val_mae: 1.9579\n",
            "Epoch 77/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.6463 - mae: 1.1797 - val_loss: 4.7842 - val_mae: 1.8143\n",
            "Epoch 78/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.6398 - mae: 1.1736 - val_loss: 4.4597 - val_mae: 1.7362\n",
            "Epoch 79/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.5943 - mae: 1.1653 - val_loss: 4.2073 - val_mae: 1.6708\n",
            "Epoch 80/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.5704 - mae: 1.1605 - val_loss: 4.3378 - val_mae: 1.7037\n",
            "Epoch 81/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.3937 - mae: 1.1450 - val_loss: 4.0800 - val_mae: 1.6481\n",
            "Epoch 82/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.5731 - mae: 1.1636 - val_loss: 4.6345 - val_mae: 1.7751\n",
            "Epoch 83/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 2.4461 - mae: 1.1495 - val_loss: 5.3680 - val_mae: 1.9481\n",
            "Epoch 84/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.5738 - mae: 1.1560 - val_loss: 5.0707 - val_mae: 1.8697\n",
            "Epoch 85/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.4603 - mae: 1.1472 - val_loss: 4.3436 - val_mae: 1.7153\n",
            "Epoch 86/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.4743 - mae: 1.1586 - val_loss: 4.3355 - val_mae: 1.7154\n",
            "Epoch 87/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 2.4801 - mae: 1.1520 - val_loss: 3.8780 - val_mae: 1.6008\n",
            "Epoch 88/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.5712 - mae: 1.1696 - val_loss: 4.0195 - val_mae: 1.6231\n",
            "Epoch 89/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.4646 - mae: 1.1458 - val_loss: 3.8975 - val_mae: 1.6080\n",
            "Epoch 90/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.4703 - mae: 1.1473 - val_loss: 3.9182 - val_mae: 1.6057\n",
            "Epoch 91/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.4508 - mae: 1.1443 - val_loss: 3.9351 - val_mae: 1.6099\n",
            "Epoch 92/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 2.4379 - mae: 1.1382 - val_loss: 4.1696 - val_mae: 1.6739\n",
            "Epoch 93/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.4511 - mae: 1.1363 - val_loss: 3.9746 - val_mae: 1.6126\n",
            "Epoch 94/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 2.5418 - mae: 1.1396 - val_loss: 5.6653 - val_mae: 1.9835\n",
            "Epoch 95/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.4836 - mae: 1.1551 - val_loss: 4.1777 - val_mae: 1.6747\n",
            "Epoch 96/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.2801 - mae: 1.1362 - val_loss: 4.1244 - val_mae: 1.6586\n",
            "Epoch 97/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.4768 - mae: 1.1318 - val_loss: 3.8964 - val_mae: 1.5810\n",
            "Epoch 98/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 2.4371 - mae: 1.1336 - val_loss: 3.6633 - val_mae: 1.5232\n",
            "Epoch 99/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.4389 - mae: 1.1317 - val_loss: 3.9112 - val_mae: 1.6005\n",
            "Epoch 100/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.4264 - mae: 1.1121 - val_loss: 3.6206 - val_mae: 1.4901\n",
            "Epoch 101/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.4592 - mae: 1.1357 - val_loss: 3.9774 - val_mae: 1.6142\n",
            "Epoch 102/800\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 2.3278 - mae: 1.1184 - val_loss: 4.8151 - val_mae: 1.7911\n",
            "Epoch 103/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.3719 - mae: 1.1224 - val_loss: 5.1821 - val_mae: 1.8859\n",
            "Epoch 104/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.3584 - mae: 1.1232 - val_loss: 5.7145 - val_mae: 2.0172\n",
            "Epoch 105/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.3869 - mae: 1.1252 - val_loss: 3.5238 - val_mae: 1.4714\n",
            "Epoch 106/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.4153 - mae: 1.1316 - val_loss: 3.8669 - val_mae: 1.5723\n",
            "Epoch 107/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.3908 - mae: 1.1160 - val_loss: 3.8282 - val_mae: 1.5324\n",
            "Epoch 108/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.3751 - mae: 1.1181 - val_loss: 3.7841 - val_mae: 1.5226\n",
            "Epoch 109/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.3751 - mae: 1.1140 - val_loss: 4.1276 - val_mae: 1.6346\n",
            "Epoch 110/800\n",
            "117/117 [==============================] - 6s 49ms/step - loss: 2.3696 - mae: 1.1302 - val_loss: 6.1712 - val_mae: 2.0864\n",
            "Epoch 111/800\n",
            "117/117 [==============================] - 6s 49ms/step - loss: 2.3090 - mae: 1.1033 - val_loss: 4.6974 - val_mae: 1.7522\n",
            "Epoch 112/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.3394 - mae: 1.1205 - val_loss: 4.2657 - val_mae: 1.6723\n",
            "Epoch 113/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.1805 - mae: 1.0738 - val_loss: 3.7962 - val_mae: 1.5396\n",
            "Epoch 114/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.1906 - mae: 1.0981 - val_loss: 4.0615 - val_mae: 1.6194\n",
            "Epoch 115/800\n",
            "117/117 [==============================] - 5s 47ms/step - loss: 2.2714 - mae: 1.0753 - val_loss: 6.1106 - val_mae: 2.0683\n",
            "Epoch 116/800\n",
            "117/117 [==============================] - 6s 51ms/step - loss: 2.3557 - mae: 1.1115 - val_loss: 3.7994 - val_mae: 1.5377\n",
            "Epoch 117/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.3545 - mae: 1.1098 - val_loss: 4.1759 - val_mae: 1.6529\n",
            "Epoch 118/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0473 - mae: 1.0617 - val_loss: 3.3737 - val_mae: 1.3990\n",
            "Epoch 119/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.3566 - mae: 1.1199 - val_loss: 4.3077 - val_mae: 1.6847\n",
            "Epoch 120/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.1643 - mae: 1.0956 - val_loss: 4.3172 - val_mae: 1.6853\n",
            "Epoch 121/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0495 - mae: 1.0608 - val_loss: 4.3049 - val_mae: 1.6780\n",
            "Epoch 122/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.2821 - mae: 1.0975 - val_loss: 4.8373 - val_mae: 1.8075\n",
            "Epoch 123/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.2411 - mae: 1.0841 - val_loss: 4.2061 - val_mae: 1.6569\n",
            "Epoch 124/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.2404 - mae: 1.0792 - val_loss: 4.4734 - val_mae: 1.7204\n",
            "Epoch 125/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 2.2549 - mae: 1.0812 - val_loss: 4.3641 - val_mae: 1.6930\n",
            "Epoch 126/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.2640 - mae: 1.0818 - val_loss: 4.4349 - val_mae: 1.7145\n",
            "Epoch 127/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.2647 - mae: 1.0910 - val_loss: 4.4328 - val_mae: 1.7085\n",
            "Epoch 128/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.2656 - mae: 1.0810 - val_loss: 4.4968 - val_mae: 1.7263\n",
            "Epoch 129/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.2606 - mae: 1.0886 - val_loss: 4.3744 - val_mae: 1.6921\n",
            "Epoch 130/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.2573 - mae: 1.0818 - val_loss: 4.6139 - val_mae: 1.7488\n",
            "Epoch 131/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.2429 - mae: 1.0794 - val_loss: 4.6123 - val_mae: 1.7458\n",
            "Epoch 132/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 2.2442 - mae: 1.0812 - val_loss: 4.6045 - val_mae: 1.7461\n",
            "Epoch 133/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.2578 - mae: 1.0841 - val_loss: 4.4558 - val_mae: 1.7102\n",
            "Epoch 134/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 2.2556 - mae: 1.0815 - val_loss: 4.5742 - val_mae: 1.7346\n",
            "Epoch 135/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.2817 - mae: 1.0826 - val_loss: 4.6053 - val_mae: 1.7400\n",
            "Epoch 136/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 2.2739 - mae: 1.0839 - val_loss: 4.6551 - val_mae: 1.7515\n",
            "Epoch 137/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 2.2638 - mae: 1.0802 - val_loss: 4.7276 - val_mae: 1.7671\n",
            "Epoch 138/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.2641 - mae: 1.0814 - val_loss: 4.5499 - val_mae: 1.7247\n",
            "Epoch 139/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.4077 - mae: 1.0947 - val_loss: 4.6281 - val_mae: 1.7462\n",
            "Epoch 140/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.3370 - mae: 1.0867 - val_loss: 4.4970 - val_mae: 1.7117\n",
            "Epoch 141/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 2.3773 - mae: 1.0900 - val_loss: 4.4900 - val_mae: 1.7100\n",
            "Epoch 142/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.3948 - mae: 1.0930 - val_loss: 4.4671 - val_mae: 1.7097\n",
            "Epoch 143/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.2969 - mae: 1.0794 - val_loss: 4.0276 - val_mae: 1.6119\n",
            "Epoch 144/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.1154 - mae: 1.0943 - val_loss: 4.2787 - val_mae: 1.6669\n",
            "Epoch 145/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.3357 - mae: 1.0845 - val_loss: 4.3405 - val_mae: 1.6775\n",
            "Epoch 146/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.3152 - mae: 1.0842 - val_loss: 4.0263 - val_mae: 1.5998\n",
            "Epoch 147/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.2901 - mae: 1.0803 - val_loss: 5.0206 - val_mae: 1.8159\n",
            "Epoch 148/800\n",
            "117/117 [==============================] - 6s 53ms/step - loss: 2.1917 - mae: 1.0920 - val_loss: 4.5243 - val_mae: 1.7252\n",
            "Epoch 149/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.2869 - mae: 1.0770 - val_loss: 4.5387 - val_mae: 1.7244\n",
            "Epoch 150/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.2752 - mae: 1.0734 - val_loss: 4.6741 - val_mae: 1.7526\n",
            "Epoch 151/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.1600 - mae: 1.0824 - val_loss: 4.7812 - val_mae: 1.7851\n",
            "Epoch 152/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 2.1409 - mae: 1.0675 - val_loss: 4.8183 - val_mae: 1.7923\n",
            "Epoch 153/800\n",
            "117/117 [==============================] - 6s 53ms/step - loss: 2.1672 - mae: 1.0658 - val_loss: 4.7642 - val_mae: 1.7791\n",
            "Epoch 154/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.1861 - mae: 1.0667 - val_loss: 4.7039 - val_mae: 1.7665\n",
            "Epoch 155/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.1982 - mae: 1.0688 - val_loss: 4.6074 - val_mae: 1.7443\n",
            "Epoch 156/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.2626 - mae: 1.0734 - val_loss: 4.6957 - val_mae: 1.7649\n",
            "Epoch 157/800\n",
            "117/117 [==============================] - 6s 47ms/step - loss: 2.2365 - mae: 1.0695 - val_loss: 4.8161 - val_mae: 1.7915\n",
            "Epoch 158/800\n",
            "117/117 [==============================] - 6s 51ms/step - loss: 2.2192 - mae: 1.0680 - val_loss: 4.8323 - val_mae: 1.7943\n",
            "Epoch 159/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.2110 - mae: 1.0673 - val_loss: 4.7769 - val_mae: 1.7806\n",
            "Epoch 160/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.2056 - mae: 1.0670 - val_loss: 4.6602 - val_mae: 1.7548\n",
            "Epoch 161/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.2006 - mae: 1.0668 - val_loss: 4.6469 - val_mae: 1.7529\n",
            "Epoch 162/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.2029 - mae: 1.0666 - val_loss: 4.5958 - val_mae: 1.7408\n",
            "Epoch 163/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.2017 - mae: 1.0663 - val_loss: 4.7081 - val_mae: 1.7677\n",
            "Epoch 164/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.2024 - mae: 1.0665 - val_loss: 4.6037 - val_mae: 1.7436\n",
            "Epoch 165/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.2139 - mae: 1.0674 - val_loss: 4.6674 - val_mae: 1.7573\n",
            "Epoch 166/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.2189 - mae: 1.0684 - val_loss: 4.6776 - val_mae: 1.7595\n",
            "Epoch 167/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.2320 - mae: 1.0700 - val_loss: 4.6993 - val_mae: 1.7629\n",
            "Epoch 168/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.2275 - mae: 1.0697 - val_loss: 4.6461 - val_mae: 1.7503\n",
            "Epoch 169/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.2317 - mae: 1.0699 - val_loss: 4.6744 - val_mae: 1.7561\n",
            "Epoch 170/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.2305 - mae: 1.0691 - val_loss: 4.6338 - val_mae: 1.7477\n",
            "Epoch 171/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.2334 - mae: 1.0694 - val_loss: 4.6245 - val_mae: 1.7466\n",
            "Epoch 172/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.2287 - mae: 1.0674 - val_loss: 4.5885 - val_mae: 1.7368\n",
            "Epoch 173/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.2434 - mae: 1.0692 - val_loss: 4.5923 - val_mae: 1.7395\n",
            "Epoch 174/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.2303 - mae: 1.0659 - val_loss: 4.5526 - val_mae: 1.7292\n",
            "Epoch 175/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.2507 - mae: 1.0686 - val_loss: 4.5164 - val_mae: 1.7205\n",
            "Epoch 176/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.2640 - mae: 1.0688 - val_loss: 4.4956 - val_mae: 1.7148\n",
            "Epoch 177/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.2845 - mae: 1.0698 - val_loss: 4.4759 - val_mae: 1.7098\n",
            "Epoch 178/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.2876 - mae: 1.0697 - val_loss: 4.4650 - val_mae: 1.7062\n",
            "Epoch 179/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.2963 - mae: 1.0706 - val_loss: 4.4299 - val_mae: 1.6974\n",
            "Epoch 180/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.2935 - mae: 1.0694 - val_loss: 4.4207 - val_mae: 1.6948\n",
            "Epoch 181/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.3191 - mae: 1.0707 - val_loss: 4.3659 - val_mae: 1.6819\n",
            "Epoch 182/800\n",
            "117/117 [==============================] - 7s 61ms/step - loss: 2.3379 - mae: 1.0715 - val_loss: 4.3224 - val_mae: 1.6720\n",
            "Epoch 183/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.3472 - mae: 1.0717 - val_loss: 4.3114 - val_mae: 1.6724\n",
            "Epoch 184/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.3333 - mae: 1.0762 - val_loss: 4.2611 - val_mae: 1.6608\n",
            "Epoch 185/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.3048 - mae: 1.0775 - val_loss: 4.3184 - val_mae: 1.6811\n",
            "Epoch 186/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.2786 - mae: 1.0681 - val_loss: 4.2387 - val_mae: 1.6615\n",
            "Epoch 187/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.2661 - mae: 1.0731 - val_loss: 4.2829 - val_mae: 1.6777\n",
            "Epoch 188/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.2503 - mae: 1.0649 - val_loss: 4.2506 - val_mae: 1.6699\n",
            "Epoch 189/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.2357 - mae: 1.0663 - val_loss: 4.2381 - val_mae: 1.6688\n",
            "Epoch 190/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.2256 - mae: 1.0625 - val_loss: 4.2440 - val_mae: 1.6729\n",
            "Epoch 191/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.2146 - mae: 1.0607 - val_loss: 4.2616 - val_mae: 1.6786\n",
            "Epoch 192/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.2056 - mae: 1.0585 - val_loss: 4.1878 - val_mae: 1.6594\n",
            "Epoch 193/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.1995 - mae: 1.0598 - val_loss: 4.2004 - val_mae: 1.6647\n",
            "Epoch 194/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.1918 - mae: 1.0551 - val_loss: 4.2083 - val_mae: 1.6671\n",
            "Epoch 195/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.1846 - mae: 1.0549 - val_loss: 4.1965 - val_mae: 1.6657\n",
            "Epoch 196/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.1806 - mae: 1.0554 - val_loss: 4.1862 - val_mae: 1.6632\n",
            "Epoch 197/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.1758 - mae: 1.0541 - val_loss: 4.2460 - val_mae: 1.6784\n",
            "Epoch 198/800\n",
            "117/117 [==============================] - 6s 56ms/step - loss: 2.1686 - mae: 1.0511 - val_loss: 4.3278 - val_mae: 1.6985\n",
            "Epoch 199/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.1641 - mae: 1.0502 - val_loss: 4.2852 - val_mae: 1.6885\n",
            "Epoch 200/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.1571 - mae: 1.0517 - val_loss: 4.3614 - val_mae: 1.7065\n",
            "Epoch 201/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.1557 - mae: 1.0514 - val_loss: 4.3630 - val_mae: 1.7071\n",
            "Epoch 202/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.1541 - mae: 1.0502 - val_loss: 4.3781 - val_mae: 1.7112\n",
            "Epoch 203/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.1465 - mae: 1.0489 - val_loss: 4.4039 - val_mae: 1.7162\n",
            "Epoch 204/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.1444 - mae: 1.0475 - val_loss: 4.3762 - val_mae: 1.7099\n",
            "Epoch 205/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 2.1358 - mae: 1.0468 - val_loss: 4.3940 - val_mae: 1.7131\n",
            "Epoch 206/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.1316 - mae: 1.0459 - val_loss: 4.4191 - val_mae: 1.7183\n",
            "Epoch 207/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.1297 - mae: 1.0448 - val_loss: 4.5385 - val_mae: 1.7452\n",
            "Epoch 208/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.1271 - mae: 1.0434 - val_loss: 4.4482 - val_mae: 1.7219\n",
            "Epoch 209/800\n",
            "117/117 [==============================] - 6s 56ms/step - loss: 2.1229 - mae: 1.0436 - val_loss: 4.4551 - val_mae: 1.7225\n",
            "Epoch 210/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.1192 - mae: 1.0410 - val_loss: 4.5361 - val_mae: 1.7407\n",
            "Epoch 211/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.1139 - mae: 1.0340 - val_loss: 4.3434 - val_mae: 1.6917\n",
            "Epoch 212/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.1066 - mae: 1.0402 - val_loss: 4.3049 - val_mae: 1.6787\n",
            "Epoch 213/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.1061 - mae: 1.0371 - val_loss: 4.3760 - val_mae: 1.6939\n",
            "Epoch 214/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.1048 - mae: 1.0310 - val_loss: 4.1783 - val_mae: 1.6393\n",
            "Epoch 215/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0981 - mae: 1.0391 - val_loss: 4.2250 - val_mae: 1.6511\n",
            "Epoch 216/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9236 - mae: 1.0339 - val_loss: 4.4986 - val_mae: 1.7266\n",
            "Epoch 217/800\n",
            "117/117 [==============================] - 6s 53ms/step - loss: 1.9314 - mae: 1.0357 - val_loss: 4.3329 - val_mae: 1.6849\n",
            "Epoch 218/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.9217 - mae: 1.0323 - val_loss: 4.3097 - val_mae: 1.6793\n",
            "Epoch 219/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9164 - mae: 1.0315 - val_loss: 4.2638 - val_mae: 1.6665\n",
            "Epoch 220/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8965 - mae: 1.0311 - val_loss: 4.2500 - val_mae: 1.6572\n",
            "Epoch 221/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8828 - mae: 1.0255 - val_loss: 4.3530 - val_mae: 1.6817\n",
            "Epoch 222/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9124 - mae: 1.0134 - val_loss: 4.4433 - val_mae: 1.7069\n",
            "Epoch 223/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.8165 - mae: 1.0177 - val_loss: 4.3057 - val_mae: 1.6726\n",
            "Epoch 224/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0406 - mae: 1.0237 - val_loss: 4.4772 - val_mae: 1.7139\n",
            "Epoch 225/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.8008 - mae: 1.0141 - val_loss: 4.5772 - val_mae: 1.7398\n",
            "Epoch 226/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0188 - mae: 1.0186 - val_loss: 4.4741 - val_mae: 1.7119\n",
            "Epoch 227/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0092 - mae: 1.0166 - val_loss: 4.5314 - val_mae: 1.7252\n",
            "Epoch 228/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0123 - mae: 1.0232 - val_loss: 4.6006 - val_mae: 1.7428\n",
            "Epoch 229/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.0019 - mae: 1.0172 - val_loss: 4.6164 - val_mae: 1.7457\n",
            "Epoch 230/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0009 - mae: 1.0178 - val_loss: 4.5160 - val_mae: 1.7197\n",
            "Epoch 231/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0020 - mae: 1.0206 - val_loss: 4.6782 - val_mae: 1.7593\n",
            "Epoch 232/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.9972 - mae: 1.0145 - val_loss: 4.6271 - val_mae: 1.7449\n",
            "Epoch 233/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9959 - mae: 1.0170 - val_loss: 4.6306 - val_mae: 1.7470\n",
            "Epoch 234/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 2.0014 - mae: 1.0112 - val_loss: 4.5538 - val_mae: 1.7274\n",
            "Epoch 235/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.9978 - mae: 1.0182 - val_loss: 4.7822 - val_mae: 1.7836\n",
            "Epoch 236/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.7700 - mae: 1.0055 - val_loss: 4.8507 - val_mae: 1.8023\n",
            "Epoch 237/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8404 - mae: 1.0154 - val_loss: 4.7269 - val_mae: 1.7727\n",
            "Epoch 238/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0605 - mae: 1.0046 - val_loss: 4.4351 - val_mae: 1.6967\n",
            "Epoch 239/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0057 - mae: 1.0184 - val_loss: 4.7875 - val_mae: 1.7821\n",
            "Epoch 240/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.7969 - mae: 1.0108 - val_loss: 4.8012 - val_mae: 1.7865\n",
            "Epoch 241/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.7753 - mae: 1.0073 - val_loss: 4.7935 - val_mae: 1.7852\n",
            "Epoch 242/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.7634 - mae: 1.0053 - val_loss: 4.7415 - val_mae: 1.7723\n",
            "Epoch 243/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0692 - mae: 1.0047 - val_loss: 4.7376 - val_mae: 1.7692\n",
            "Epoch 244/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.0352 - mae: 1.0089 - val_loss: 4.8044 - val_mae: 1.7864\n",
            "Epoch 245/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.0123 - mae: 1.0179 - val_loss: 4.8806 - val_mae: 1.8051\n",
            "Epoch 246/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.0415 - mae: 1.0014 - val_loss: 4.8066 - val_mae: 1.7856\n",
            "Epoch 247/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0103 - mae: 1.0194 - val_loss: 4.9453 - val_mae: 1.8200\n",
            "Epoch 248/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 2.0114 - mae: 1.0016 - val_loss: 4.8244 - val_mae: 1.7894\n",
            "Epoch 249/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.7790 - mae: 1.0056 - val_loss: 4.9225 - val_mae: 1.8146\n",
            "Epoch 250/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.8069 - mae: 1.0079 - val_loss: 4.9069 - val_mae: 1.8121\n",
            "Epoch 251/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8458 - mae: 1.0058 - val_loss: 4.9904 - val_mae: 1.8312\n",
            "Epoch 252/800\n",
            "117/117 [==============================] - 5s 47ms/step - loss: 1.7658 - mae: 0.9990 - val_loss: 4.9236 - val_mae: 1.8172\n",
            "Epoch 253/800\n",
            "117/117 [==============================] - 6s 52ms/step - loss: 2.0228 - mae: 0.9999 - val_loss: 4.9332 - val_mae: 1.8177\n",
            "Epoch 254/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.7827 - mae: 1.0035 - val_loss: 5.0576 - val_mae: 1.8450\n",
            "Epoch 255/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.0237 - mae: 1.0016 - val_loss: 5.0163 - val_mae: 1.8373\n",
            "Epoch 256/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.7660 - mae: 1.0005 - val_loss: 5.0190 - val_mae: 1.8375\n",
            "Epoch 257/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 1.7453 - mae: 0.9974 - val_loss: 4.9697 - val_mae: 1.8291\n",
            "Epoch 258/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.9848 - mae: 1.0091 - val_loss: 5.0390 - val_mae: 1.8438\n",
            "Epoch 259/800\n",
            "117/117 [==============================] - 6s 56ms/step - loss: 1.9805 - mae: 1.0023 - val_loss: 5.0633 - val_mae: 1.8478\n",
            "Epoch 260/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.9784 - mae: 1.0137 - val_loss: 5.1232 - val_mae: 1.8620\n",
            "Epoch 261/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9607 - mae: 1.0040 - val_loss: 5.2251 - val_mae: 1.8851\n",
            "Epoch 262/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9551 - mae: 1.0052 - val_loss: 5.2313 - val_mae: 1.8861\n",
            "Epoch 263/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9510 - mae: 1.0043 - val_loss: 5.1667 - val_mae: 1.8723\n",
            "Epoch 264/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.9463 - mae: 0.9987 - val_loss: 5.0944 - val_mae: 1.8558\n",
            "Epoch 265/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9493 - mae: 1.0057 - val_loss: 5.1510 - val_mae: 1.8691\n",
            "Epoch 266/800\n",
            "117/117 [==============================] - 7s 61ms/step - loss: 1.9416 - mae: 0.9995 - val_loss: 5.1199 - val_mae: 1.8621\n",
            "Epoch 267/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.9434 - mae: 1.0034 - val_loss: 5.1569 - val_mae: 1.8701\n",
            "Epoch 268/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9449 - mae: 1.0044 - val_loss: 5.0565 - val_mae: 1.8470\n",
            "Epoch 269/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.9430 - mae: 1.0050 - val_loss: 5.0672 - val_mae: 1.8490\n",
            "Epoch 270/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9367 - mae: 1.0011 - val_loss: 5.0038 - val_mae: 1.8348\n",
            "Epoch 271/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.7718 - mae: 0.9955 - val_loss: 4.8582 - val_mae: 1.8076\n",
            "Epoch 272/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 1.7750 - mae: 0.9959 - val_loss: 4.7105 - val_mae: 1.7763\n",
            "Epoch 273/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.7648 - mae: 0.9937 - val_loss: 4.5970 - val_mae: 1.7503\n",
            "Epoch 274/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.7157 - mae: 0.9857 - val_loss: 4.6528 - val_mae: 1.7608\n",
            "Epoch 275/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.7267 - mae: 0.9871 - val_loss: 4.8555 - val_mae: 1.8054\n",
            "Epoch 276/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 1.7145 - mae: 0.9861 - val_loss: 4.9912 - val_mae: 1.8355\n",
            "Epoch 277/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.7228 - mae: 0.9864 - val_loss: 5.1630 - val_mae: 1.8740\n",
            "Epoch 278/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9869 - mae: 0.9958 - val_loss: 5.2991 - val_mae: 1.9024\n",
            "Epoch 279/800\n",
            "117/117 [==============================] - 6s 48ms/step - loss: 1.9243 - mae: 1.0025 - val_loss: 5.6295 - val_mae: 1.9721\n",
            "Epoch 280/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 1.9296 - mae: 1.0071 - val_loss: 5.6810 - val_mae: 1.9832\n",
            "Epoch 281/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.9217 - mae: 1.0050 - val_loss: 5.7936 - val_mae: 2.0064\n",
            "Epoch 282/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.9169 - mae: 1.0035 - val_loss: 5.7056 - val_mae: 1.9887\n",
            "Epoch 283/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.9069 - mae: 0.9985 - val_loss: 5.6091 - val_mae: 1.9678\n",
            "Epoch 284/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9018 - mae: 0.9964 - val_loss: 5.5226 - val_mae: 1.9485\n",
            "Epoch 285/800\n",
            "117/117 [==============================] - 6s 48ms/step - loss: 1.9081 - mae: 0.9993 - val_loss: 5.2859 - val_mae: 1.8980\n",
            "Epoch 286/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 1.6961 - mae: 0.9783 - val_loss: 5.0139 - val_mae: 1.8408\n",
            "Epoch 287/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8926 - mae: 0.9932 - val_loss: 5.1436 - val_mae: 1.8657\n",
            "Epoch 288/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 1.9044 - mae: 0.9882 - val_loss: 4.5449 - val_mae: 1.7293\n",
            "Epoch 289/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.8957 - mae: 0.9977 - val_loss: 5.2770 - val_mae: 1.8924\n",
            "Epoch 290/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.9027 - mae: 0.9991 - val_loss: 5.1893 - val_mae: 1.8730\n",
            "Epoch 291/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8975 - mae: 0.9906 - val_loss: 4.6636 - val_mae: 1.7554\n",
            "Epoch 292/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.8920 - mae: 0.9967 - val_loss: 4.9995 - val_mae: 1.8302\n",
            "Epoch 293/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.8949 - mae: 0.9970 - val_loss: 5.0558 - val_mae: 1.8421\n",
            "Epoch 294/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.8953 - mae: 0.9970 - val_loss: 4.9703 - val_mae: 1.8221\n",
            "Epoch 295/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8930 - mae: 0.9966 - val_loss: 4.9632 - val_mae: 1.8193\n",
            "Epoch 296/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.8931 - mae: 0.9970 - val_loss: 4.9829 - val_mae: 1.8227\n",
            "Epoch 297/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8929 - mae: 0.9973 - val_loss: 4.9548 - val_mae: 1.8151\n",
            "Epoch 298/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8931 - mae: 0.9976 - val_loss: 4.6459 - val_mae: 1.7439\n",
            "Epoch 299/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 1.8873 - mae: 0.9966 - val_loss: 4.7835 - val_mae: 1.7754\n",
            "Epoch 300/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8910 - mae: 0.9966 - val_loss: 4.9006 - val_mae: 1.8007\n",
            "Epoch 301/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 1.8850 - mae: 0.9970 - val_loss: 4.9119 - val_mae: 1.8021\n",
            "Epoch 302/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8857 - mae: 0.9973 - val_loss: 4.7491 - val_mae: 1.7656\n",
            "Epoch 303/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8833 - mae: 0.9961 - val_loss: 4.6914 - val_mae: 1.7514\n",
            "Epoch 304/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.8810 - mae: 0.9967 - val_loss: 4.9038 - val_mae: 1.7985\n",
            "Epoch 305/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8805 - mae: 0.9972 - val_loss: 4.7998 - val_mae: 1.7746\n",
            "Epoch 306/800\n",
            "117/117 [==============================] - 7s 61ms/step - loss: 1.8784 - mae: 0.9966 - val_loss: 4.6294 - val_mae: 1.7349\n",
            "Epoch 307/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.8750 - mae: 0.9962 - val_loss: 4.9205 - val_mae: 1.8004\n",
            "Epoch 308/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8713 - mae: 0.9973 - val_loss: 4.8125 - val_mae: 1.7756\n",
            "Epoch 309/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8712 - mae: 0.9967 - val_loss: 4.6054 - val_mae: 1.7274\n",
            "Epoch 310/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.8679 - mae: 0.9965 - val_loss: 4.9355 - val_mae: 1.8012\n",
            "Epoch 311/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8661 - mae: 0.9978 - val_loss: 4.6004 - val_mae: 1.7242\n",
            "Epoch 312/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8636 - mae: 0.9965 - val_loss: 4.6946 - val_mae: 1.7452\n",
            "Epoch 313/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.8610 - mae: 0.9968 - val_loss: 4.9412 - val_mae: 1.7996\n",
            "Epoch 314/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8584 - mae: 0.9983 - val_loss: 4.7029 - val_mae: 1.7453\n",
            "Epoch 315/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8544 - mae: 0.9963 - val_loss: 4.7532 - val_mae: 1.7564\n",
            "Epoch 316/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8513 - mae: 0.9969 - val_loss: 4.6237 - val_mae: 1.7261\n",
            "Epoch 317/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.8497 - mae: 0.9967 - val_loss: 4.8013 - val_mae: 1.7658\n",
            "Epoch 318/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8452 - mae: 0.9969 - val_loss: 4.6772 - val_mae: 1.7373\n",
            "Epoch 319/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 1.8434 - mae: 0.9960 - val_loss: 4.6782 - val_mae: 1.7369\n",
            "Epoch 320/800\n",
            "117/117 [==============================] - 5s 47ms/step - loss: 1.8399 - mae: 0.9963 - val_loss: 4.7198 - val_mae: 1.7455\n",
            "Epoch 321/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.8382 - mae: 0.9965 - val_loss: 4.6714 - val_mae: 1.7339\n",
            "Epoch 322/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8356 - mae: 0.9964 - val_loss: 4.7053 - val_mae: 1.7407\n",
            "Epoch 323/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8343 - mae: 0.9971 - val_loss: 4.6881 - val_mae: 1.7364\n",
            "Epoch 324/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8319 - mae: 0.9968 - val_loss: 4.8204 - val_mae: 1.7661\n",
            "Epoch 325/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8304 - mae: 0.9980 - val_loss: 4.5875 - val_mae: 1.7123\n",
            "Epoch 326/800\n",
            "117/117 [==============================] - 7s 62ms/step - loss: 1.8267 - mae: 0.9964 - val_loss: 4.9271 - val_mae: 1.7880\n",
            "Epoch 327/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8253 - mae: 0.9984 - val_loss: 4.8144 - val_mae: 1.7632\n",
            "Epoch 328/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.8233 - mae: 0.9980 - val_loss: 4.8413 - val_mae: 1.7690\n",
            "Epoch 329/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.8200 - mae: 0.9981 - val_loss: 4.9339 - val_mae: 1.7884\n",
            "Epoch 330/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8187 - mae: 0.9988 - val_loss: 4.8299 - val_mae: 1.7660\n",
            "Epoch 331/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8185 - mae: 0.9991 - val_loss: 4.9532 - val_mae: 1.7920\n",
            "Epoch 332/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8180 - mae: 1.0001 - val_loss: 4.8504 - val_mae: 1.7689\n",
            "Epoch 333/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8157 - mae: 0.9995 - val_loss: 5.0263 - val_mae: 1.8066\n",
            "Epoch 334/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.8174 - mae: 1.0015 - val_loss: 4.8766 - val_mae: 1.7757\n",
            "Epoch 335/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8154 - mae: 1.0008 - val_loss: 5.0004 - val_mae: 1.8021\n",
            "Epoch 336/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8146 - mae: 1.0015 - val_loss: 5.0607 - val_mae: 1.8148\n",
            "Epoch 337/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8119 - mae: 1.0013 - val_loss: 4.8552 - val_mae: 1.7695\n",
            "Epoch 338/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.8100 - mae: 1.0002 - val_loss: 5.1172 - val_mae: 1.8272\n",
            "Epoch 339/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8157 - mae: 1.0035 - val_loss: 4.7783 - val_mae: 1.7529\n",
            "Epoch 340/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8091 - mae: 1.0004 - val_loss: 5.0735 - val_mae: 1.8176\n",
            "Epoch 341/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8150 - mae: 1.0038 - val_loss: 5.0766 - val_mae: 1.8186\n",
            "Epoch 342/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.8106 - mae: 1.0022 - val_loss: 4.9551 - val_mae: 1.7921\n",
            "Epoch 343/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8115 - mae: 1.0024 - val_loss: 4.9350 - val_mae: 1.7874\n",
            "Epoch 344/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8131 - mae: 1.0032 - val_loss: 4.9803 - val_mae: 1.7967\n",
            "Epoch 345/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8143 - mae: 1.0040 - val_loss: 4.7890 - val_mae: 1.7526\n",
            "Epoch 346/800\n",
            "117/117 [==============================] - 6s 48ms/step - loss: 1.8112 - mae: 1.0022 - val_loss: 4.9747 - val_mae: 1.7936\n",
            "Epoch 347/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8154 - mae: 1.0047 - val_loss: 4.8711 - val_mae: 1.7705\n",
            "Epoch 348/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8120 - mae: 1.0024 - val_loss: 4.9288 - val_mae: 1.7832\n",
            "Epoch 349/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8165 - mae: 1.0046 - val_loss: 4.9207 - val_mae: 1.7811\n",
            "Epoch 350/800\n",
            "117/117 [==============================] - 6s 49ms/step - loss: 1.8156 - mae: 1.0039 - val_loss: 4.9545 - val_mae: 1.7880\n",
            "Epoch 351/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8192 - mae: 1.0053 - val_loss: 4.7992 - val_mae: 1.7523\n",
            "Epoch 352/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 1.8186 - mae: 1.0043 - val_loss: 4.9538 - val_mae: 1.7869\n",
            "Epoch 353/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8226 - mae: 1.0063 - val_loss: 4.8202 - val_mae: 1.7564\n",
            "Epoch 354/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.8203 - mae: 1.0047 - val_loss: 4.7956 - val_mae: 1.7506\n",
            "Epoch 355/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8268 - mae: 1.0071 - val_loss: 4.7671 - val_mae: 1.7431\n",
            "Epoch 356/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8250 - mae: 1.0059 - val_loss: 4.7220 - val_mae: 1.7324\n",
            "Epoch 357/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8302 - mae: 1.0078 - val_loss: 4.7652 - val_mae: 1.7418\n",
            "Epoch 358/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 1.8307 - mae: 1.0074 - val_loss: 4.9325 - val_mae: 1.7793\n",
            "Epoch 359/800\n",
            "117/117 [==============================] - 7s 64ms/step - loss: 1.8334 - mae: 1.0088 - val_loss: 4.7401 - val_mae: 1.7352\n",
            "Epoch 360/800\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 1.8324 - mae: 1.0073 - val_loss: 4.6864 - val_mae: 1.7220\n",
            "Epoch 361/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8375 - mae: 1.0089 - val_loss: 4.6580 - val_mae: 1.7158\n",
            "Epoch 362/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 1.8392 - mae: 1.0091 - val_loss: 4.8061 - val_mae: 1.7488\n",
            "Epoch 363/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8418 - mae: 1.0105 - val_loss: 4.5320 - val_mae: 1.6859\n",
            "Epoch 364/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8434 - mae: 1.0101 - val_loss: 4.5855 - val_mae: 1.6965\n",
            "Epoch 365/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.8449 - mae: 1.0106 - val_loss: 4.5679 - val_mae: 1.6915\n",
            "Epoch 366/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 1.8470 - mae: 1.0111 - val_loss: 4.5370 - val_mae: 1.6846\n",
            "Epoch 367/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8489 - mae: 1.0114 - val_loss: 4.6329 - val_mae: 1.7065\n",
            "Epoch 368/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8511 - mae: 1.0122 - val_loss: 4.4753 - val_mae: 1.6690\n",
            "Epoch 369/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8543 - mae: 1.0128 - val_loss: 4.4683 - val_mae: 1.6672\n",
            "Epoch 370/800\n",
            "117/117 [==============================] - 6s 49ms/step - loss: 1.8565 - mae: 1.0133 - val_loss: 4.4586 - val_mae: 1.6643\n",
            "Epoch 371/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8603 - mae: 1.0143 - val_loss: 4.4475 - val_mae: 1.6609\n",
            "Epoch 372/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.8612 - mae: 1.0142 - val_loss: 4.4144 - val_mae: 1.6529\n",
            "Epoch 373/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8649 - mae: 1.0154 - val_loss: 4.4265 - val_mae: 1.6551\n",
            "Epoch 374/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.8670 - mae: 1.0157 - val_loss: 4.3942 - val_mae: 1.6470\n",
            "Epoch 375/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8708 - mae: 1.0166 - val_loss: 4.3754 - val_mae: 1.6421\n",
            "Epoch 376/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.8720 - mae: 1.0167 - val_loss: 4.3467 - val_mae: 1.6354\n",
            "Epoch 377/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.8771 - mae: 1.0180 - val_loss: 4.3438 - val_mae: 1.6341\n",
            "Epoch 378/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.8777 - mae: 1.0178 - val_loss: 4.2653 - val_mae: 1.6154\n",
            "Epoch 379/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.8850 - mae: 1.0198 - val_loss: 4.2506 - val_mae: 1.6122\n",
            "Epoch 380/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8866 - mae: 1.0199 - val_loss: 4.2274 - val_mae: 1.6065\n",
            "Epoch 381/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.8914 - mae: 1.0210 - val_loss: 4.2005 - val_mae: 1.5997\n",
            "Epoch 382/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.8951 - mae: 1.0218 - val_loss: 4.1719 - val_mae: 1.5925\n",
            "Epoch 383/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.8985 - mae: 1.0226 - val_loss: 4.1445 - val_mae: 1.5850\n",
            "Epoch 384/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.8994 - mae: 1.0225 - val_loss: 4.1085 - val_mae: 1.5761\n",
            "Epoch 385/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.9028 - mae: 1.0233 - val_loss: 4.0821 - val_mae: 1.5702\n",
            "Epoch 386/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9061 - mae: 1.0240 - val_loss: 4.0634 - val_mae: 1.5658\n",
            "Epoch 387/800\n",
            "117/117 [==============================] - 6s 49ms/step - loss: 1.9088 - mae: 1.0246 - val_loss: 4.0412 - val_mae: 1.5609\n",
            "Epoch 388/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9118 - mae: 1.0252 - val_loss: 4.0304 - val_mae: 1.5578\n",
            "Epoch 389/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.9127 - mae: 1.0251 - val_loss: 4.0035 - val_mae: 1.5508\n",
            "Epoch 390/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9159 - mae: 1.0258 - val_loss: 3.9883 - val_mae: 1.5473\n",
            "Epoch 391/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.9178 - mae: 1.0258 - val_loss: 3.9795 - val_mae: 1.5447\n",
            "Epoch 392/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9210 - mae: 1.0266 - val_loss: 3.9724 - val_mae: 1.5419\n",
            "Epoch 393/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9226 - mae: 1.0267 - val_loss: 3.9704 - val_mae: 1.5420\n",
            "Epoch 394/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9257 - mae: 1.0273 - val_loss: 3.9542 - val_mae: 1.5378\n",
            "Epoch 395/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.9271 - mae: 1.0274 - val_loss: 3.9520 - val_mae: 1.5368\n",
            "Epoch 396/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 1.9301 - mae: 1.0281 - val_loss: 3.9530 - val_mae: 1.5365\n",
            "Epoch 397/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9309 - mae: 1.0280 - val_loss: 3.9592 - val_mae: 1.5371\n",
            "Epoch 398/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9347 - mae: 1.0290 - val_loss: 3.9461 - val_mae: 1.5331\n",
            "Epoch 399/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9364 - mae: 1.0292 - val_loss: 3.9497 - val_mae: 1.5322\n",
            "Epoch 400/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.9408 - mae: 1.0305 - val_loss: 3.9421 - val_mae: 1.5290\n",
            "Epoch 401/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.9437 - mae: 1.0312 - val_loss: 3.9432 - val_mae: 1.5287\n",
            "Epoch 402/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.9472 - mae: 1.0322 - val_loss: 3.9172 - val_mae: 1.5236\n",
            "Epoch 403/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.9503 - mae: 1.0330 - val_loss: 3.8975 - val_mae: 1.5186\n",
            "Epoch 404/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.9522 - mae: 1.0333 - val_loss: 3.8932 - val_mae: 1.5172\n",
            "Epoch 405/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9534 - mae: 1.0335 - val_loss: 3.8973 - val_mae: 1.5185\n",
            "Epoch 406/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9553 - mae: 1.0334 - val_loss: 3.8863 - val_mae: 1.5151\n",
            "Epoch 407/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 1.9540 - mae: 1.0334 - val_loss: 3.8940 - val_mae: 1.5173\n",
            "Epoch 408/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9557 - mae: 1.0336 - val_loss: 3.9105 - val_mae: 1.5205\n",
            "Epoch 409/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9555 - mae: 1.0333 - val_loss: 3.9223 - val_mae: 1.5232\n",
            "Epoch 410/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 1.9576 - mae: 1.0338 - val_loss: 3.9193 - val_mae: 1.5227\n",
            "Epoch 411/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9599 - mae: 1.0343 - val_loss: 3.9127 - val_mae: 1.5212\n",
            "Epoch 412/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 1.9580 - mae: 1.0340 - val_loss: 3.9285 - val_mae: 1.5259\n",
            "Epoch 413/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9611 - mae: 1.0341 - val_loss: 3.9133 - val_mae: 1.5215\n",
            "Epoch 414/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.9579 - mae: 1.0333 - val_loss: 3.9248 - val_mae: 1.5247\n",
            "Epoch 415/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9595 - mae: 1.0335 - val_loss: 3.9320 - val_mae: 1.5253\n",
            "Epoch 416/800\n",
            "117/117 [==============================] - 6s 49ms/step - loss: 1.9629 - mae: 1.0341 - val_loss: 3.9377 - val_mae: 1.5253\n",
            "Epoch 417/800\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 1.9616 - mae: 1.0343 - val_loss: 3.9492 - val_mae: 1.5293\n",
            "Epoch 418/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9649 - mae: 1.0348 - val_loss: 3.9542 - val_mae: 1.5303\n",
            "Epoch 419/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 1.9665 - mae: 1.0354 - val_loss: 3.9602 - val_mae: 1.5324\n",
            "Epoch 420/800\n",
            "117/117 [==============================] - 5s 47ms/step - loss: 1.9678 - mae: 1.0358 - val_loss: 3.9766 - val_mae: 1.5362\n",
            "Epoch 421/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9718 - mae: 1.0368 - val_loss: 3.9837 - val_mae: 1.5393\n",
            "Epoch 422/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9715 - mae: 1.0369 - val_loss: 3.9949 - val_mae: 1.5438\n",
            "Epoch 423/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 1.9736 - mae: 1.0370 - val_loss: 3.9985 - val_mae: 1.5460\n",
            "Epoch 424/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9743 - mae: 1.0376 - val_loss: 4.0102 - val_mae: 1.5510\n",
            "Epoch 425/800\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 1.9763 - mae: 1.0374 - val_loss: 4.0021 - val_mae: 1.5500\n",
            "Epoch 426/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9770 - mae: 1.0379 - val_loss: 4.0254 - val_mae: 1.5579\n",
            "Epoch 427/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 1.9792 - mae: 1.0379 - val_loss: 4.0222 - val_mae: 1.5580\n",
            "Epoch 428/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9804 - mae: 1.0388 - val_loss: 4.0599 - val_mae: 1.5714\n",
            "Epoch 429/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 1.9812 - mae: 1.0384 - val_loss: 4.0672 - val_mae: 1.5746\n",
            "Epoch 430/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 1.9829 - mae: 1.0394 - val_loss: 4.0825 - val_mae: 1.5805\n",
            "Epoch 431/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 1.9853 - mae: 1.0396 - val_loss: 4.0805 - val_mae: 1.5789\n",
            "Epoch 432/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.9872 - mae: 1.0407 - val_loss: 4.1024 - val_mae: 1.5870\n",
            "Epoch 433/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 1.9895 - mae: 1.0402 - val_loss: 4.0917 - val_mae: 1.5840\n",
            "Epoch 434/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9904 - mae: 1.0411 - val_loss: 4.1160 - val_mae: 1.5917\n",
            "Epoch 435/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.9933 - mae: 1.0409 - val_loss: 4.0977 - val_mae: 1.5865\n",
            "Epoch 436/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9915 - mae: 1.0415 - val_loss: 4.1392 - val_mae: 1.5989\n",
            "Epoch 437/800\n",
            "117/117 [==============================] - 6s 47ms/step - loss: 1.9951 - mae: 1.0411 - val_loss: 4.1032 - val_mae: 1.5890\n",
            "Epoch 438/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9945 - mae: 1.0422 - val_loss: 4.1412 - val_mae: 1.6010\n",
            "Epoch 439/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 1.9966 - mae: 1.0414 - val_loss: 4.1094 - val_mae: 1.5925\n",
            "Epoch 440/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.9960 - mae: 1.0420 - val_loss: 4.1296 - val_mae: 1.5984\n",
            "Epoch 441/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9997 - mae: 1.0417 - val_loss: 4.1229 - val_mae: 1.5971\n",
            "Epoch 442/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 1.9978 - mae: 1.0421 - val_loss: 4.1044 - val_mae: 1.5925\n",
            "Epoch 443/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0005 - mae: 1.0426 - val_loss: 4.1107 - val_mae: 1.5957\n",
            "Epoch 444/800\n",
            "117/117 [==============================] - 7s 62ms/step - loss: 1.9945 - mae: 1.0412 - val_loss: 4.1371 - val_mae: 1.6039\n",
            "Epoch 445/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9985 - mae: 1.0414 - val_loss: 4.1046 - val_mae: 1.5961\n",
            "Epoch 446/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.0012 - mae: 1.0426 - val_loss: 4.1451 - val_mae: 1.6081\n",
            "Epoch 447/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9973 - mae: 1.0414 - val_loss: 4.1078 - val_mae: 1.5984\n",
            "Epoch 448/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0050 - mae: 1.0424 - val_loss: 4.0973 - val_mae: 1.5960\n",
            "Epoch 449/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0033 - mae: 1.0427 - val_loss: 4.0775 - val_mae: 1.5909\n",
            "Epoch 450/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0066 - mae: 1.0427 - val_loss: 4.0242 - val_mae: 1.5759\n",
            "Epoch 451/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0096 - mae: 1.0440 - val_loss: 4.0770 - val_mae: 1.5930\n",
            "Epoch 452/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0000 - mae: 1.0412 - val_loss: 3.9981 - val_mae: 1.5683\n",
            "Epoch 453/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0115 - mae: 1.0435 - val_loss: 4.0483 - val_mae: 1.5852\n",
            "Epoch 454/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0048 - mae: 1.0423 - val_loss: 3.9981 - val_mae: 1.5685\n",
            "Epoch 455/800\n",
            "117/117 [==============================] - 7s 62ms/step - loss: 2.0156 - mae: 1.0447 - val_loss: 4.0367 - val_mae: 1.5817\n",
            "Epoch 456/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0089 - mae: 1.0434 - val_loss: 4.0238 - val_mae: 1.5787\n",
            "Epoch 457/800\n",
            "117/117 [==============================] - 6s 47ms/step - loss: 2.0116 - mae: 1.0436 - val_loss: 4.0485 - val_mae: 1.5865\n",
            "Epoch 458/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0069 - mae: 1.0422 - val_loss: 3.9953 - val_mae: 1.5702\n",
            "Epoch 459/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 2.0191 - mae: 1.0447 - val_loss: 4.0196 - val_mae: 1.5770\n",
            "Epoch 460/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0131 - mae: 1.0435 - val_loss: 4.0635 - val_mae: 1.5924\n",
            "Epoch 461/800\n",
            "117/117 [==============================] - 7s 62ms/step - loss: 2.0054 - mae: 1.0416 - val_loss: 4.0523 - val_mae: 1.5883\n",
            "Epoch 462/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0152 - mae: 1.0433 - val_loss: 4.0157 - val_mae: 1.5775\n",
            "Epoch 463/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0179 - mae: 1.0436 - val_loss: 4.0594 - val_mae: 1.5925\n",
            "Epoch 464/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0058 - mae: 1.0413 - val_loss: 4.0702 - val_mae: 1.5964\n",
            "Epoch 465/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 2.0128 - mae: 1.0420 - val_loss: 4.0162 - val_mae: 1.5790\n",
            "Epoch 466/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0177 - mae: 1.0430 - val_loss: 4.0489 - val_mae: 1.5918\n",
            "Epoch 467/800\n",
            "117/117 [==============================] - 6s 51ms/step - loss: 2.0043 - mae: 1.0403 - val_loss: 4.0129 - val_mae: 1.5798\n",
            "Epoch 468/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0147 - mae: 1.0421 - val_loss: 4.0425 - val_mae: 1.5905\n",
            "Epoch 469/800\n",
            "117/117 [==============================] - 7s 62ms/step - loss: 2.0067 - mae: 1.0400 - val_loss: 3.9891 - val_mae: 1.5739\n",
            "Epoch 470/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0172 - mae: 1.0427 - val_loss: 4.0310 - val_mae: 1.5878\n",
            "Epoch 471/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 2.0050 - mae: 1.0395 - val_loss: 4.0393 - val_mae: 1.5905\n",
            "Epoch 472/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0133 - mae: 1.0412 - val_loss: 3.9742 - val_mae: 1.5695\n",
            "Epoch 473/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0158 - mae: 1.0412 - val_loss: 4.0296 - val_mae: 1.5896\n",
            "Epoch 474/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0089 - mae: 1.0405 - val_loss: 3.9787 - val_mae: 1.5722\n",
            "Epoch 475/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 2.0165 - mae: 1.0412 - val_loss: 4.0179 - val_mae: 1.5869\n",
            "Epoch 476/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0061 - mae: 1.0397 - val_loss: 4.0009 - val_mae: 1.5812\n",
            "Epoch 477/800\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 2.0135 - mae: 1.0403 - val_loss: 3.9602 - val_mae: 1.5668\n",
            "Epoch 478/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0154 - mae: 1.0406 - val_loss: 4.0113 - val_mae: 1.5862\n",
            "Epoch 479/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 2.0116 - mae: 1.0409 - val_loss: 3.9757 - val_mae: 1.5720\n",
            "Epoch 480/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0142 - mae: 1.0396 - val_loss: 4.0008 - val_mae: 1.5828\n",
            "Epoch 481/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0144 - mae: 1.0410 - val_loss: 3.9530 - val_mae: 1.5640\n",
            "Epoch 482/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0123 - mae: 1.0386 - val_loss: 3.9899 - val_mae: 1.5804\n",
            "Epoch 483/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0166 - mae: 1.0422 - val_loss: 3.9495 - val_mae: 1.5631\n",
            "Epoch 484/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 2.0109 - mae: 1.0386 - val_loss: 4.0095 - val_mae: 1.5858\n",
            "Epoch 485/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 2.0186 - mae: 1.0422 - val_loss: 3.9475 - val_mae: 1.5628\n",
            "Epoch 486/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 2.0082 - mae: 1.0380 - val_loss: 4.0048 - val_mae: 1.5856\n",
            "Epoch 487/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0174 - mae: 1.0418 - val_loss: 3.9377 - val_mae: 1.5596\n",
            "Epoch 488/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0096 - mae: 1.0379 - val_loss: 4.0014 - val_mae: 1.5838\n",
            "Epoch 489/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0195 - mae: 1.0419 - val_loss: 3.9400 - val_mae: 1.5598\n",
            "Epoch 490/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.0099 - mae: 1.0375 - val_loss: 3.9831 - val_mae: 1.5783\n",
            "Epoch 491/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 2.0173 - mae: 1.0414 - val_loss: 3.9337 - val_mae: 1.5588\n",
            "Epoch 492/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 2.0081 - mae: 1.0367 - val_loss: 3.9739 - val_mae: 1.5760\n",
            "Epoch 493/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0167 - mae: 1.0406 - val_loss: 3.9348 - val_mae: 1.5584\n",
            "Epoch 494/800\n",
            "117/117 [==============================] - 6s 49ms/step - loss: 2.0053 - mae: 1.0358 - val_loss: 3.9756 - val_mae: 1.5779\n",
            "Epoch 495/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0184 - mae: 1.0405 - val_loss: 3.9280 - val_mae: 1.5564\n",
            "Epoch 496/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0045 - mae: 1.0352 - val_loss: 3.9572 - val_mae: 1.5719\n",
            "Epoch 497/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0179 - mae: 1.0402 - val_loss: 3.9236 - val_mae: 1.5574\n",
            "Epoch 498/800\n",
            "117/117 [==============================] - 7s 61ms/step - loss: 2.0032 - mae: 1.0345 - val_loss: 3.9539 - val_mae: 1.5708\n",
            "Epoch 499/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0167 - mae: 1.0394 - val_loss: 3.9149 - val_mae: 1.5550\n",
            "Epoch 500/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9988 - mae: 1.0337 - val_loss: 3.9479 - val_mae: 1.5700\n",
            "Epoch 501/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0152 - mae: 1.0387 - val_loss: 3.9134 - val_mae: 1.5545\n",
            "Epoch 502/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0021 - mae: 1.0341 - val_loss: 3.9461 - val_mae: 1.5698\n",
            "Epoch 503/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0160 - mae: 1.0382 - val_loss: 3.9088 - val_mae: 1.5530\n",
            "Epoch 504/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0044 - mae: 1.0342 - val_loss: 3.9332 - val_mae: 1.5662\n",
            "Epoch 505/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0174 - mae: 1.0382 - val_loss: 3.9026 - val_mae: 1.5522\n",
            "Epoch 506/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.0057 - mae: 1.0342 - val_loss: 3.9340 - val_mae: 1.5679\n",
            "Epoch 507/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0205 - mae: 1.0386 - val_loss: 3.8937 - val_mae: 1.5504\n",
            "Epoch 508/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0100 - mae: 1.0344 - val_loss: 3.9189 - val_mae: 1.5641\n",
            "Epoch 509/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.0203 - mae: 1.0383 - val_loss: 3.8848 - val_mae: 1.5484\n",
            "Epoch 510/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0094 - mae: 1.0341 - val_loss: 3.8830 - val_mae: 1.5542\n",
            "Epoch 511/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.0152 - mae: 1.0368 - val_loss: 3.8749 - val_mae: 1.5494\n",
            "Epoch 512/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0132 - mae: 1.0349 - val_loss: 3.8661 - val_mae: 1.5503\n",
            "Epoch 513/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0148 - mae: 1.0359 - val_loss: 3.8609 - val_mae: 1.5469\n",
            "Epoch 514/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.0142 - mae: 1.0349 - val_loss: 3.8488 - val_mae: 1.5445\n",
            "Epoch 515/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0056 - mae: 1.0335 - val_loss: 3.8489 - val_mae: 1.5458\n",
            "Epoch 516/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.0065 - mae: 1.0338 - val_loss: 3.8509 - val_mae: 1.5478\n",
            "Epoch 517/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.0105 - mae: 1.0344 - val_loss: 3.8404 - val_mae: 1.5451\n",
            "Epoch 518/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.0102 - mae: 1.0338 - val_loss: 3.8422 - val_mae: 1.5459\n",
            "Epoch 519/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0118 - mae: 1.0343 - val_loss: 3.8384 - val_mae: 1.5461\n",
            "Epoch 520/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0157 - mae: 1.0348 - val_loss: 3.8254 - val_mae: 1.5426\n",
            "Epoch 521/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0124 - mae: 1.0343 - val_loss: 3.8739 - val_mae: 1.5611\n",
            "Epoch 522/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.0234 - mae: 1.0361 - val_loss: 3.8227 - val_mae: 1.5409\n",
            "Epoch 523/800\n",
            "117/117 [==============================] - 6s 53ms/step - loss: 2.0126 - mae: 1.0333 - val_loss: 3.8162 - val_mae: 1.5422\n",
            "Epoch 524/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.0158 - mae: 1.0347 - val_loss: 3.8251 - val_mae: 1.5442\n",
            "Epoch 525/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0162 - mae: 1.0344 - val_loss: 3.8732 - val_mae: 1.5616\n",
            "Epoch 526/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.0210 - mae: 1.0354 - val_loss: 3.8067 - val_mae: 1.5385\n",
            "Epoch 527/800\n",
            "117/117 [==============================] - 6s 47ms/step - loss: 2.0140 - mae: 1.0334 - val_loss: 3.8489 - val_mae: 1.5542\n",
            "Epoch 528/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0244 - mae: 1.0363 - val_loss: 3.8051 - val_mae: 1.5404\n",
            "Epoch 529/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0207 - mae: 1.0349 - val_loss: 3.8126 - val_mae: 1.5442\n",
            "Epoch 530/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0215 - mae: 1.0354 - val_loss: 3.8269 - val_mae: 1.5486\n",
            "Epoch 531/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.0243 - mae: 1.0359 - val_loss: 3.8076 - val_mae: 1.5449\n",
            "Epoch 532/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0217 - mae: 1.0351 - val_loss: 3.8002 - val_mae: 1.5432\n",
            "Epoch 533/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0235 - mae: 1.0358 - val_loss: 3.8204 - val_mae: 1.5500\n",
            "Epoch 534/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0277 - mae: 1.0368 - val_loss: 3.8112 - val_mae: 1.5476\n",
            "Epoch 535/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0295 - mae: 1.0371 - val_loss: 3.8022 - val_mae: 1.5457\n",
            "Epoch 536/800\n",
            "117/117 [==============================] - 7s 61ms/step - loss: 2.0261 - mae: 1.0365 - val_loss: 3.8014 - val_mae: 1.5461\n",
            "Epoch 537/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0254 - mae: 1.0365 - val_loss: 3.8075 - val_mae: 1.5493\n",
            "Epoch 538/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0261 - mae: 1.0367 - val_loss: 3.8094 - val_mae: 1.5506\n",
            "Epoch 539/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 2.0289 - mae: 1.0375 - val_loss: 3.8113 - val_mae: 1.5521\n",
            "Epoch 540/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0284 - mae: 1.0372 - val_loss: 3.8148 - val_mae: 1.5540\n",
            "Epoch 541/800\n",
            "117/117 [==============================] - 6s 56ms/step - loss: 2.0297 - mae: 1.0376 - val_loss: 3.8051 - val_mae: 1.5517\n",
            "Epoch 542/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0284 - mae: 1.0373 - val_loss: 3.8141 - val_mae: 1.5544\n",
            "Epoch 543/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0283 - mae: 1.0372 - val_loss: 3.7967 - val_mae: 1.5501\n",
            "Epoch 544/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.0254 - mae: 1.0365 - val_loss: 3.8120 - val_mae: 1.5549\n",
            "Epoch 545/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.0272 - mae: 1.0369 - val_loss: 3.8144 - val_mae: 1.5558\n",
            "Epoch 546/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0274 - mae: 1.0369 - val_loss: 3.8228 - val_mae: 1.5573\n",
            "Epoch 547/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0308 - mae: 1.0377 - val_loss: 3.8232 - val_mae: 1.5588\n",
            "Epoch 548/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0285 - mae: 1.0365 - val_loss: 3.8245 - val_mae: 1.5590\n",
            "Epoch 549/800\n",
            "117/117 [==============================] - 6s 52ms/step - loss: 2.0301 - mae: 1.0371 - val_loss: 3.8334 - val_mae: 1.5605\n",
            "Epoch 550/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0304 - mae: 1.0365 - val_loss: 3.8453 - val_mae: 1.5631\n",
            "Epoch 551/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 2.0303 - mae: 1.0367 - val_loss: 3.8285 - val_mae: 1.5600\n",
            "Epoch 552/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0311 - mae: 1.0364 - val_loss: 3.8569 - val_mae: 1.5666\n",
            "Epoch 553/800\n",
            "117/117 [==============================] - 6s 54ms/step - loss: 2.0317 - mae: 1.0361 - val_loss: 3.8370 - val_mae: 1.5616\n",
            "Epoch 554/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0321 - mae: 1.0364 - val_loss: 3.8454 - val_mae: 1.5634\n",
            "Epoch 555/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0318 - mae: 1.0359 - val_loss: 3.8364 - val_mae: 1.5619\n",
            "Epoch 556/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0301 - mae: 1.0361 - val_loss: 3.8438 - val_mae: 1.5642\n",
            "Epoch 557/800\n",
            "117/117 [==============================] - 6s 48ms/step - loss: 2.0301 - mae: 1.0355 - val_loss: 3.8594 - val_mae: 1.5678\n",
            "Epoch 558/800\n",
            "117/117 [==============================] - 6s 48ms/step - loss: 2.0319 - mae: 1.0363 - val_loss: 3.8569 - val_mae: 1.5679\n",
            "Epoch 559/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0323 - mae: 1.0364 - val_loss: 3.8485 - val_mae: 1.5663\n",
            "Epoch 560/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0323 - mae: 1.0360 - val_loss: 3.8503 - val_mae: 1.5661\n",
            "Epoch 561/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0324 - mae: 1.0360 - val_loss: 3.8427 - val_mae: 1.5647\n",
            "Epoch 562/800\n",
            "117/117 [==============================] - 6s 48ms/step - loss: 2.0286 - mae: 1.0357 - val_loss: 3.8613 - val_mae: 1.5703\n",
            "Epoch 563/800\n",
            "117/117 [==============================] - 5s 41ms/step - loss: 2.0312 - mae: 1.0357 - val_loss: 3.8438 - val_mae: 1.5654\n",
            "Epoch 564/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.0268 - mae: 1.0351 - val_loss: 3.8620 - val_mae: 1.5709\n",
            "Epoch 565/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0286 - mae: 1.0348 - val_loss: 3.8514 - val_mae: 1.5677\n",
            "Epoch 566/800\n",
            "117/117 [==============================] - 5s 47ms/step - loss: 2.0242 - mae: 1.0343 - val_loss: 3.8836 - val_mae: 1.5774\n",
            "Epoch 567/800\n",
            "117/117 [==============================] - 5s 43ms/step - loss: 2.0323 - mae: 1.0358 - val_loss: 3.8591 - val_mae: 1.5698\n",
            "Epoch 568/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0250 - mae: 1.0338 - val_loss: 3.8923 - val_mae: 1.5796\n",
            "Epoch 569/800\n",
            "117/117 [==============================] - 5s 42ms/step - loss: 2.0317 - mae: 1.0352 - val_loss: 3.8780 - val_mae: 1.5757\n",
            "Epoch 570/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0241 - mae: 1.0335 - val_loss: 3.8801 - val_mae: 1.5768\n",
            "Epoch 571/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 2.0195 - mae: 1.0324 - val_loss: 3.9142 - val_mae: 1.5860\n",
            "Epoch 572/800\n",
            "117/117 [==============================] - 7s 57ms/step - loss: 2.0167 - mae: 1.0318 - val_loss: 3.9235 - val_mae: 1.5884\n",
            "Epoch 573/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0132 - mae: 1.0304 - val_loss: 3.9518 - val_mae: 1.5962\n",
            "Epoch 574/800\n",
            "117/117 [==============================] - 7s 62ms/step - loss: 2.0127 - mae: 1.0303 - val_loss: 3.9094 - val_mae: 1.5855\n",
            "Epoch 575/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0124 - mae: 1.0294 - val_loss: 3.9099 - val_mae: 1.5853\n",
            "Epoch 576/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 2.0088 - mae: 1.0283 - val_loss: 3.9391 - val_mae: 1.5930\n",
            "Epoch 577/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0056 - mae: 1.0282 - val_loss: 3.9206 - val_mae: 1.5893\n",
            "Epoch 578/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0052 - mae: 1.0274 - val_loss: 3.9283 - val_mae: 1.5911\n",
            "Epoch 579/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0024 - mae: 1.0267 - val_loss: 3.9540 - val_mae: 1.5983\n",
            "Epoch 580/800\n",
            "117/117 [==============================] - 6s 48ms/step - loss: 2.0114 - mae: 1.0280 - val_loss: 3.9350 - val_mae: 1.5934\n",
            "Epoch 581/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 2.0105 - mae: 1.0271 - val_loss: 3.9163 - val_mae: 1.5882\n",
            "Epoch 582/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 2.0003 - mae: 1.0256 - val_loss: 4.0156 - val_mae: 1.6142\n",
            "Epoch 583/800\n",
            "117/117 [==============================] - 7s 61ms/step - loss: 2.0003 - mae: 1.0256 - val_loss: 3.9367 - val_mae: 1.5935\n",
            "Epoch 584/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 1.9976 - mae: 1.0247 - val_loss: 3.9535 - val_mae: 1.5981\n",
            "Epoch 585/800\n",
            "117/117 [==============================] - 6s 52ms/step - loss: 1.9925 - mae: 1.0238 - val_loss: 4.0132 - val_mae: 1.6141\n",
            "Epoch 586/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 2.0017 - mae: 1.0251 - val_loss: 3.9943 - val_mae: 1.6092\n",
            "Epoch 587/800\n",
            "117/117 [==============================] - 7s 62ms/step - loss: 1.9951 - mae: 1.0236 - val_loss: 4.0024 - val_mae: 1.6114\n",
            "Epoch 588/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.9964 - mae: 1.0237 - val_loss: 4.0074 - val_mae: 1.6128\n",
            "Epoch 589/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 2.0000 - mae: 1.0248 - val_loss: 3.9978 - val_mae: 1.6110\n",
            "Epoch 590/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9953 - mae: 1.0239 - val_loss: 4.0520 - val_mae: 1.6252\n",
            "Epoch 591/800\n",
            "117/117 [==============================] - 7s 59ms/step - loss: 2.0011 - mae: 1.0243 - val_loss: 4.0265 - val_mae: 1.6184\n",
            "Epoch 592/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9994 - mae: 1.0239 - val_loss: 4.0036 - val_mae: 1.6129\n",
            "Epoch 593/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 1.9937 - mae: 1.0233 - val_loss: 4.0181 - val_mae: 1.6171\n",
            "Epoch 594/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9937 - mae: 1.0236 - val_loss: 4.0238 - val_mae: 1.6185\n",
            "Epoch 595/800\n",
            "117/117 [==============================] - 7s 63ms/step - loss: 1.9945 - mae: 1.0238 - val_loss: 4.0300 - val_mae: 1.6204\n",
            "Epoch 596/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 1.9894 - mae: 1.0232 - val_loss: 4.0637 - val_mae: 1.6289\n",
            "Epoch 597/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.9962 - mae: 1.0235 - val_loss: 4.0440 - val_mae: 1.6233\n",
            "Epoch 598/800\n",
            "117/117 [==============================] - 5s 45ms/step - loss: 1.9917 - mae: 1.0230 - val_loss: 4.0243 - val_mae: 1.6187\n",
            "Epoch 599/800\n",
            "117/117 [==============================] - 7s 58ms/step - loss: 1.9847 - mae: 1.0222 - val_loss: 4.0624 - val_mae: 1.6284\n",
            "Epoch 600/800\n",
            "117/117 [==============================] - 6s 48ms/step - loss: 1.9810 - mae: 1.0219 - val_loss: 4.1034 - val_mae: 1.6389\n",
            "Epoch 601/800\n",
            "117/117 [==============================] - 6s 50ms/step - loss: 1.9838 - mae: 1.0217 - val_loss: 4.0894 - val_mae: 1.6351\n",
            "Epoch 602/800\n",
            "117/117 [==============================] - 6s 55ms/step - loss: 1.9878 - mae: 1.0220 - val_loss: 4.0547 - val_mae: 1.6259\n",
            "Epoch 603/800\n",
            "117/117 [==============================] - 7s 60ms/step - loss: 1.9805 - mae: 1.0215 - val_loss: 4.0722 - val_mae: 1.6304\n",
            "Epoch 604/800\n",
            "117/117 [==============================] - 5s 44ms/step - loss: 1.9834 - mae: 1.0223 - val_loss: 4.0999 - val_mae: 1.6373\n",
            "Epoch 605/800\n",
            "117/117 [==============================] - 7s 56ms/step - loss: 1.9759 - mae: 1.0212 - val_loss: 4.1765 - val_mae: 1.6561\n",
            "Epoch 606/800\n",
            "117/117 [==============================] - 5s 46ms/step - loss: 1.9780 - mae: 1.0203 - val_loss: 4.1575 - val_mae: 1.6511\n",
            "Epoch 607/800\n",
            "117/117 [==============================] - ETA: 0s - loss: 1.9762 - mae: 1.0202"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7f26af92efd2>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history = model.fit(train_dataset,\n\u001b[0m\u001b[1;32m      9\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     validation_data=val_dataset)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1854\u001b[0m                             \u001b[0mpss_evaluation_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pss_evaluation_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m                         )\n\u001b[0;32m-> 1856\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1857\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2283\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautotune_steps_per_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m             for (\n\u001b[0m\u001b[1;32m   2286\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m             \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 706\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    743\u001b[0m             self._flat_output_types)\n\u001b[1;32m    744\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3420\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3421\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3422\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3423\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.LSTM(64)(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=100,\n",
        "                    validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history[\"mae\"]\n",
        "val_loss = history.history[\"val_mae\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
        "plt.title(\"Training and validation MAE\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "gDs-hcU6pN3U",
        "outputId": "0b59a602-3312-48bc-8dad-d1bcc83dd29f"
      },
      "id": "gDs-hcU6pN3U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}